{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd9d0d8",
   "metadata": {},
   "source": [
    "# Sensitivity & Specificity\n",
    "\n",
    "YT video - https://www.youtube.com/watch?v=vP06aMoz4v8&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=4\n",
    "\n",
    "### Sensitivity (True Positive Rate):\n",
    "\n",
    "The proportion of actual positive cases that were correctly identified\n",
    "\n",
    "Formula: TP / (TP + FN)\n",
    "\n",
    "Measures how well the model identifies people who actually have the condition\n",
    "\n",
    "### Specificity (True Negative Rate):\n",
    "\n",
    "The proportion of actual negative cases that were correctly identified\n",
    "\n",
    "Formula: TN / (TN + FP)\n",
    "\n",
    "Measures how well the model identifies people who don't have the condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc6192",
   "metadata": {},
   "source": [
    "### Calculating Sensitivity & Specificity - Binary Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98637d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TN: 67, FP: 2\n",
      "FN: 9, TP: 22\n",
      "\n",
      "Sensitivity = 22 / (22 + 9) = 0.710 (71.0%)\n",
      "Specificity = 67 / (67 + 2) = 0.971 (97.1%)\n",
      "\n",
      "Interpretation:\n",
      "- 71.0% of actual positive cases were correctly identified\n",
      "- 97.1% of actual negative cases were correctly identified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = np.array([[67, 2], [9, 22]])\n",
    "\n",
    "# Extract values from confusion confusion_matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate Sensitivity (True positive rate)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Calculate Specificity (True Negative rate)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"TN: {tn}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TP: {tp}\")\n",
    "print(f\"\\nSensitivity = {tp} / ({tp} + {fn}) = {sensitivity:.3f} ({sensitivity*100:.1f}%)\")\n",
    "print(f\"Specificity = {tn} / ({tn} + {fp}) = {specificity:.3f} ({specificity*100:.1f}%)\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- {sensitivity*100:.1f}% of actual positive cases were correctly identified\")\n",
    "print(f\"- {specificity*100:.1f}% of actual negative cases were correctly identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c6581",
   "metadata": {},
   "source": [
    "### Multi-class Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c831ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class Confusion Matrix:\n",
      "Predicted:  Healthy  Mild  Severe\n",
      "Actual:\n",
      "Healthy     45      5      0\n",
      "Mild         3     32      5\n",
      "Severe       0      2      8\n",
      "\n",
      "Healthy Sensitivity = 45 / (45 + 5) = 0.900 (90.0%)\n",
      "\n",
      "Mild Sensitivity = 32 / (32 + 8) = 0.800 (80.0%)\n",
      "\n",
      "Severe Sensitivity = 8 / (8 + 2) = 0.800 (80.0%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Multi-class example: Disease classification (Healthy, Mild, Severe)\n",
    "\n",
    "# Example: 3-class confusion matrix (Healthy=0, Mild=1, Severe=2)\n",
    "cm_multi = np.array([[45, 5, 0],    # Healthy patients\n",
    "                     [3, 32, 5],     # Mild patients  \n",
    "                     [0, 2, 8]])     # Severe patients\n",
    "\n",
    "print(\"Multi-class Confusion Matrix:\")\n",
    "print(\"Predicted:  Healthy  Mild  Severe\")\n",
    "print(\"Actual:\")\n",
    "print(f\"Healthy    {cm_multi[0,0]:3d}    {cm_multi[0,1]:3d}    {cm_multi[0,2]:3d}\")\n",
    "print(f\"Mild       {cm_multi[1,0]:3d}    {cm_multi[1,1]:3d}    {cm_multi[1,2]:3d}\")\n",
    "print(f\"Severe     {cm_multi[2,0]:3d}    {cm_multi[2,1]:3d}    {cm_multi[2,2]:3d}\")\n",
    "\n",
    "# Calculate sensitivity for each class (one-vs-rest approach)\n",
    "for i, class_name in enumerate(['Healthy', 'Mild', 'Severe']):\n",
    "    # True positives for this class\n",
    "    tp = cm_multi[i, i]\n",
    "    # False negatives (sum of row minus true positives)\n",
    "    fn = np.sum(cm_multi[i, :]) - tp\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{class_name} Sensitivity = {tp} / ({tp} + {fn}) = {sensitivity:.3f} ({sensitivity*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd142298",
   "metadata": {},
   "source": [
    "Trade-off Relationship: Sensitivity and specificity often have an inverse relationship - improving one typically decreases the other\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
