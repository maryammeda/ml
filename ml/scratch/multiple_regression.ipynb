{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ce1763",
   "metadata": {},
   "source": [
    "# Multiple Regression\n",
    "\n",
    "YT Video - https://www.youtube.com/watch?v=zITIFTsivN8&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=11\n",
    "\n",
    "Multiple Regression is where we use more than one variable to predict our target. Instead of just fitting a line, we're now fitting a plane (with two variables) or a \"higher-dimensional object\" (with more than two). We use multiple regression is what you use when you think **multiple factors** might influence an outcome.\n",
    "* If we add another variable to our model, the equation just gets a little longer : `Body length = y-intercept + slope1 +* Mouse Weight + slope2 * Tail Length`\n",
    "\n",
    "Lets add tail_ lnegth to our data and build a new model using the same Scikit_learn Component, **LinearRegression**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f29196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multiple Regression ---\n",
      "Intercept: 6.12\n",
      "Coefficients (for Mouse Weight and Tail Length): [0.48484848 3.86363636]\n",
      "Equation: Body Length = 6.12 + (0.48 * Mouse_Weight) + (3.86 * Tail_Length)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Make data with two independent variables (Mouse Weight and Tail Length) and one dependent variable (Body Length)\n",
    "mouse_weight = np.array([18, 20, 22, 24, 26, 28, 30, 32])\n",
    "tail_length = np.array([7.0, 7.2, 7.5, 7.8, 8.0, 8.1, 8.3, 8.5])\n",
    "body_length = np.array([42, 44, 45, 48, 50, 51, 52, 55])\n",
    "\n",
    "# Combine two features into a single 2D array\n",
    "X_multiple = np.c_[mouse_weight, tail_length]\n",
    "\n",
    "# Create and fit the multiple regression model\n",
    "multiple_model = LinearRegression()\n",
    "multiple_model.fit(X_multiple, body_length)\n",
    "\n",
    "# New results \n",
    "print(\"\\n--- Multiple Regression ---\")\n",
    "print(f\"Intercept: {multiple_model.intercept_:.2f}\")\n",
    "print(f\"Coefficients (for Mouse Weight and Tail Length): {multiple_model.coef_}\")\n",
    "print(f\"Equation: Body Length = {multiple_model.intercept_:.2f} + ({multiple_model.coef_[0]:.2f} * Mouse_Weight) + ({multiple_model.coef_[1]:.2f} * Tail_Length)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83785528",
   "metadata": {},
   "source": [
    "### Measuring the fit: R-Squared (R²)\n",
    "\n",
    "R-squared tells you how much of the variation in the target (Body Length) is explained by your model. A value is 1.0 is a perfect fit. The good news is that calculating R² is the exact same for both simple and multiple regression. You're still just comparing how much better your fit is than just guessing the average body length every time.\n",
    "\n",
    "**Scikit_Learn component** : `r2_score`\n",
    "* To get this value, scikit-learn gives us a handy function in its metrics module called `r2_score`. Alternatively, you can just call the `.score()` method directly on your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466fce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model R-squared (mouse weight): 0.98\n",
      "Multiple Model R-squared (mouse weight and tail length): 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Reshape the single feature into a 2D array\n",
    "X_simple = mouse_weight.reshape(-1, 1)\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_simple, body_length)\n",
    "simple_r2 = simple_model.score(X_simple, body_length)\n",
    "\n",
    "# Multiple models r-squared\n",
    "multiple_r2 = multiple_model.score(X_multiple, body_length)\n",
    "\n",
    "# Print results\n",
    "print(f\"Simple Model R-squared (mouse weight): {simple_r2:.2f}\")\n",
    "print(f\"Multiple Model R-squared (mouse weight and tail length): {multiple_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6728015",
   "metadata": {},
   "source": [
    "Notice the R² value went up when we added Tail Length. This means the new model explains more of the variation in Body Length. \n",
    "\n",
    "# The F-test\n",
    "\n",
    "With the F-test we can directly compare the simple model to the multiple model to see if adding the trail_length gave us a statistically significant improvement..\n",
    "* A statistical test to see if the improvement in R² between a simple model and a more complex model is big enough to be meaningful, or if it could have happened by random chance.\n",
    "* Instead of comparing our model to the `mean`, we now compare the **multiple regression** model to the **simple regression** model. We're replacing the mean stuff in the F-value equation with the simple regression stuff.\n",
    "* `F = (Improvement in Fit) / (Remaining Unexplained Variation)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aec7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison F-test ---\n",
      "F-statistic: 1.3917\n",
      "P-value: 0.2912\n",
      "\n",
      "The p-value is not small. Adding Tail Length did not significantly improve the model.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "# Calculate the Sum of Squared errors for both models\n",
    "ss_simple = np.sum((body_length - simple_model.predict(X_simple))**2)\n",
    "ss_multiple = np.sum((body_length - multiple_model.predict(X_multiple))**2)\n",
    "\n",
    "# 2 parameters: intercept and slope for weight\n",
    "p_simple = 2\n",
    "# Multiple model has 3: intercept, slope for weight, slope for tail length\n",
    "p_multiple = 3\n",
    "# Number of data points\n",
    "n = len(body_length)\n",
    "\n",
    "# Calculate the F-statistic using the formula from the video\n",
    "numerator = (ss_simple - ss_multiple) / (p_multiple - p_simple)\n",
    "denominator = ss_multiple / (n - p_multiple)\n",
    "f_statistic = numerator / denominator\n",
    "\n",
    "# Calculate the p-value from the F-statistic\n",
    "p_value = 1 - f.cdf(f_statistic, dfn=(p_multiple - p_simple), dfd=(n - p_multiple))\n",
    "\n",
    "print(\"\\n--- Model Comparison F-test ---\")\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nThe p-value is small! Adding Tail Length to the model was worth the trouble.\")\n",
    "else:\n",
    "    print(\"\\nThe p-value is not small. Adding Tail Length did not significantly improve the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7752adc",
   "metadata": {},
   "source": [
    "If the p-value is small (traditionally less than 0.05), it means the improvement we saw in R² is statistically significant. We can be confident that adding the tail length data made our model meaningfully better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
